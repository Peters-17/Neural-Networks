{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ad0755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def get_data_loader(training = True):\n",
    "    #Input: an optional boolean argument (default value is True for training dataset)\n",
    "    #RETURNS: Dataloader for the training set (if training = True) or the test set (if training = False)\n",
    "    transform= transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    train_set=datasets.FashionMNIST('./data',train=True,download=True,transform=transform)\n",
    "    test_set=datasets.FashionMNIST('./data', train=False,transform=transform)\n",
    "    loader = None\n",
    "    if(training == True):\n",
    "        loader = torch.utils.data.DataLoader(train_set, batch_size = 64)\n",
    "    else:\n",
    "        loader = torch.utils.data.DataLoader(test_set, shuffle=False, batch_size = 64)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b2148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = nn.Sequential(nn.Flatten(), nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ed9a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, T):\n",
    "    opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    model.train()\n",
    "    for Epoch in range(T):\n",
    "        output = ''\n",
    "        lossValue = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            opt.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            lossValue += loss.item()\n",
    "        correctValue = 0\n",
    "        totalValue = 0\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            totalValue += labels.size(0)\n",
    "            correctValue += (predicted == labels).sum().item()\n",
    "        output += 'Train Epoch: ' + str(Epoch) + '   Accuracy: ' + str(correctValue) + '/' + str(totalValue)\n",
    "        percent = '{0:.2f}'.format((100*correctValue)/totalValue) + '%'\n",
    "        output += '(' + percent + ') Loss: ' + '{0:.3f}'.format(lossValue/totalValue)\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09bb9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, show_loss=True):\n",
    "    opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    model.eval()\n",
    "    lossValue = 0.0\n",
    "    correctValue = 0\n",
    "    totalValue = 0\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        opt.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        lossValue += loss.item()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            totalValue += labels.size(0)\n",
    "            correctValue += (predicted == labels).sum().item()\n",
    "        if show_loss:\n",
    "            print('Average loss: ' + '{0:.4f}'.format(lossValue/totalValue))\n",
    "        print('Accuracy: ' + '{0:.2f}'.format(100*correctValue/totalValue) + '%')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2b5d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(model, test_images, index):\n",
    "    #logits = model(test_images[index])\n",
    "    #prob = F.softmax(logits, dim=1)\n",
    "    #arr = prob.detach().numpy()[0] \n",
    "    #maxIndex = [-1, -1, -1]\n",
    "    #clone = list(arr)\n",
    "    #for j in range(3):\n",
    "    #    for i in range(len(arr)):\n",
    "    #        if i != maxIndex[0] and i != maxIndex[1] and i != maxIndex[2]:        \n",
    "    #            if arr[i] == max(clone):\n",
    "    #                maxIndex[j] = i\n",
    "    #                clone.remove(max(clone))\n",
    "    #                break\n",
    "    class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
    "    #for index in maxIndex:\n",
    "    #    print(class_names[index] + ': ' + '{0:.2f}'.format(100*arr[index]) + '%')\n",
    "    pred_result = model(test_images[index])\n",
    "    prob = F.softmax(pred_result.flatten(), dim=0)\n",
    "    list = list(torch.argsort(prob))[::-1]\n",
    "    print(\"{:s}:{:.2%}\".format(class_names[list[0]], prob[list[0]]))\n",
    "    print(\"{:s}:{:.2%}\".format(class_names[list[1]], prob[list[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77194c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeb45554",
   "metadata": {},
   "outputs": [],
   "source": [
    " train_loader = get_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1b25395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    " print(type(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edca6940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    " print(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "639ac325",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_data_loader(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f004e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cad4a56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f31c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d482949",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1830de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8335a9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10852/4202352444.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10852/291081785.py\u001b[0m in \u001b[0;36mpredict_label\u001b[1;34m(model, test_images, index)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#for index in maxIndex:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#    print(class_names[index] + ': ' + '{0:.2f}'.format(100*arr[index]) + '%')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mpred_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "predict_label(model, test_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efd290e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 Accuracy: 41315/60000(68.86%) Loss: 0.92\n",
      "Train Epoch: 1 Accuracy: 49171/60000(81.95%) Loss: 0.514\n",
      "Train Epoch: 2 Accuracy: 50430/60000(84.05%) Loss: 0.456\n",
      "Train Epoch: 3 Accuracy: 51084/60000(85.14%) Loss: 0.424\n",
      "Train Epoch: 4 Accuracy: 51549/60000(85.91%) Loss: 0.401\n",
      "Average loss: 0.4298\n",
      "Accuracy: 84.63%\n",
      "Sneaker: 99.20%\n",
      "Sandal: 0.39%\n",
      "Ankle Boot: 0.35%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feel free to import other packages, if needed.\n",
    "# As long as they are supported by CSL machines.\n",
    "\n",
    "\n",
    "def get_data_loader(training = True):\n",
    "    \"\"\"\n",
    "    TODO: implement this function.\n",
    "\n",
    "    INPUT: \n",
    "        An optional boolean argument (default value is True for training dataset)\n",
    "\n",
    "    RETURNS:\n",
    "        Dataloader for the training set (if training = True) or the test set (if training = False)\n",
    "    \"\"\"\n",
    "\n",
    "    custom_transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    train_set=datasets.FashionMNIST('./data',train=True, download=True,transform=custom_transform)\n",
    "    test_set=datasets.FashionMNIST('./data', train=False, transform=custom_transform)\n",
    "    \n",
    "    if(training == True):\n",
    "        loader = torch.utils.data.DataLoader(train_set, batch_size = 64)\n",
    "    else:\n",
    "        loader = torch.utils.data.DataLoader(test_set, shuffle=False, batch_size = 64)\n",
    "    return loader\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "    TODO: implement this function.\n",
    "\n",
    "    INPUT: \n",
    "        None\n",
    "\n",
    "    RETURNS:\n",
    "        An untrained neural network model\n",
    "    \"\"\"\n",
    "    model = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(28*28, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 10)\n",
    "        )\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_loader, criterion, T):\n",
    "    \"\"\"\n",
    "    TODO: implement this function.\n",
    "\n",
    "    INPUT: \n",
    "        model - the model produced by the previous function\n",
    "        train_loader  - the train DataLoader produced by the first function\n",
    "        criterion   - cross-entropy \n",
    "        T - number of epochs for training\n",
    "\n",
    "    RETURNS:\n",
    "        None\n",
    "    \"\"\"\n",
    "    opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(T):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        batches = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            batches += 1\n",
    "            inputs, labels = data\n",
    "            opt.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            running_loss += loss.item()\n",
    "        percent = \"{:.2%}\".format(correct/total)\n",
    "        loss = round(running_loss/batches,3) #TODO: check the denominator\n",
    "        print(f\"Train Epoch: {epoch} Accuracy: {correct}/{total}({percent}) Loss: {loss}\")\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, show_loss = True):\n",
    "    \"\"\"\n",
    "    TODO: implement this function.\n",
    "\n",
    "    INPUT: \n",
    "        model - the the trained model produced by the previous function\n",
    "        test_loader    - the test DataLoader\n",
    "        criterion   - cropy-entropy \n",
    "\n",
    "    RETURNS:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    batches = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs \n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            batches += 1\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        percent = \"{:.2%}\".format(correct/total)\n",
    "        loss = round(running_loss/batches,4) #TODO: check the denominator\n",
    "        if(show_loss == True):\n",
    "            print(f\"Average loss: {loss}\")\n",
    "            print(f\"Accuracy: {percent}\")\n",
    "        else:\n",
    "            print(f\"Accuracy: {percent}\")\n",
    "\n",
    "\n",
    "def predict_label(model, test_images, index):\n",
    "    \"\"\"\n",
    "    TODO: implement this function.\n",
    "\n",
    "    INPUT: \n",
    "        model - the trained model\n",
    "        test_images   -  test image set of shape Nx1x28x28\n",
    "        index   -  specific index  i of the image to be tested: 0 <= i <= N - 1\n",
    "\n",
    "\n",
    "    RETURNS:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    pred_result = model(test_images[index])\n",
    "    prob = F.softmax(pred_result.flatten(), dim=0)\n",
    "    sort_list = list(torch.argsort(prob))[::-1]\n",
    "    class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt', 'Sneaker', 'Bag','Ankle Boot']\n",
    "    print(\"{:s}: {:.2%}\".format(class_names[sort_list[0]], prob[sort_list[0]]))\n",
    "    print(\"{:s}: {:.2%}\".format(class_names[sort_list[1]], prob[sort_list[1]]))\n",
    "    print(\"{:s}: {:.2%}\".format(class_names[sort_list[2]], prob[sort_list[2]]))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    Feel free to write your own test code here to exaime the correctness of your functions. \n",
    "    Note that this part will not be graded.\n",
    "    '''\n",
    "    train_loader = get_data_loader()\n",
    "    test_loader = get_data_loader(False)\n",
    "#     print(type(test_loader))\n",
    "#     print(test_loader.dataset)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = build_model()\n",
    "    train_model(model, train_loader, criterion, T = 5)\n",
    "    evaluate_model(model, test_loader, criterion, show_loss = True)\n",
    "    tester = next(iter(test_loader))[0]\n",
    "    predict_label(model, tester, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab8965be",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10852/4202352444.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10852/3694318203.py\u001b[0m in \u001b[0;36mpredict_label\u001b[1;34m(model, test_images, index)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \"\"\"\n\u001b[0;32m    146\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     \u001b[0mpred_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0msort_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "predict_label(model, test_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9c255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
